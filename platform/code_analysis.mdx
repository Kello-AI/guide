---
title: "Code Sight"
icon: "fa-code"
description: "A smart, unbiased snapshot of a candidateâ€™s real coding work"
sidebarTitle: "Code Sight"
---

Hiring great engineers shouldn't mean endless problem statements and evaluation loops.\
**Code Sight** is our way of solving that â€” by doing what every hiring manager wishes they had time for: actually reading the candidateâ€™s code.

## The problem

Letâ€™s be honest. For engineering roles, we all want to hire based on real skill. Which usually means sending a problem statement, waiting for submissions, reviewing code, and hoping the best candidates even bother to apply in the first place.

But there's a catch:

- **Reviewing code takes serious bandwidth** â€” not scalable when youâ€™ve got 100\+ applicants
- **Top candidates often donâ€™t want to do take-homes** â€” especially when their GitHub speaks for itself
- **It's hard to evaluate real-world engineering skills from a coding test alone**

Meanwhile, great candidates are already showing us their work â€” in GitHub repos, public projects, and open-source contributions. They expect us to look.

**Code Sight** does exactly that. It reviews candidatesâ€™ real code for you â€” deeply, objectively, and at scale.

## What Code Sight does

**Code Sight reviews a candidateâ€™s actual code** so you donâ€™t have to â€” and gives you a clean report anyone on the team can understand.

For every engineering applicant who shares a GitHub profile or links to projects, we:

- Scan their **public GitHub repositories**
- Analyze only the code **they actually wrote**
- Run deep scans to check for quality, hygiene, and test discipline
- Summarize the findings in plain English â€” not dev-speak

Think of it as a â€œcode-based resume,â€ but way more honest.

## What youâ€™ll see

### ğŸ› ï¸ Tech Stack & Experience

For each candidate, youâ€™ll see:

- **Languages, tools & frameworks** theyâ€™ve used (e.g. Python, TypeScript, AWS, LangChain)
- **How much theyâ€™ve coded** in each (line counts & project counts)
- **When they last used it**
- **Estimated real-world experience** (we track active 14-day streaks across time)

<Tip>
  We also highlight **matches with the job requirements** so you know whoâ€™s already working with your stack.
</Tip>

![image.png](/images/image.png)

## ğŸ“¦ Project-by-project insights

For each project the candidate has talked about in their resume, we run a deep scan and show:

#### âœ… Pass / Fail Quality Gate

A simple signal that tells you:

> Is this project production-ready?\
> This is computed from a deep scan of their codebase (using SonarQube \+ our own models).

Great for quick filtering.

#### Code Quality Ratings

- **Maintainability rating**: Is the code modular and clean?
- **Reliability rating**: Are there signs of bugs or runtime risks?
- **Security rating**: Any red flags around vulnerable patterns?
- **Critical issues count**: High \+ blocker issues

| Rating  | What It Means                | Should You Be Concerned?    |
| :------ | :--------------------------- | :-------------------------- |
| **A**   | Clean, production-level code | âœ… No concerns               |
| **B**   | Mostly solid, some flaws     | âš ï¸ Worth a closer look      |
| **Câ€“E** | Technical debt, risky        | ğŸš« May need to deprioritize |

#### Code Hygiene

- **Commit Hygiene**: Are the commits small and descriptive (verb \+ scope)?
- **Test Discipline**: Did the candidate write any tests?
- **Comment Hygiene**: Are comments clear, helpful, and present?
- **Duplicate Code**: How much code is repeated unnecessarily?

![Kello Code Sight Repo Analysis Pn](/images/kello_code_sight_repo_analysis.png)

## ğŸ”¥ How to use this in hiring

Code Sight is built for speed **and** depth.\
Hereâ€™s how teams use it today:

- **Recruiters** use the tech stack \+ Quality Gate to do first-round shortlisting
- **Hiring managers** dive into the code hygiene and quality metrics for signal
- **HR teams** can now present â€œportfolio strengthâ€ alongside resumes

This lets you skip the problem statement (or reserve it for final round), and focus on candidates whoâ€™ve already proven they can code.

---

## Current Limitations

- We donâ€™t scan **private GitHub repos**
- We donâ€™t analyze **Codeforces / Leetcode** accounts yet (coming soon)
- We donâ€™t currently evaluate **design patterns or system design skills** from code

But for writing clean, maintainable, real-world code â€” weâ€™ve got you covered.

---

## FAQs

<AccordionGroup>
  <Accordion title="How we compute it" icon="sparkles">
    ## How we compute it\!

    - Code quality metrics are derived from **SonarQube** \+ our in-house code models
    - Tech stack & languages are inferred **only from the candidateâ€™s commits** (not the whole repo)
    - We analyze **only public repos** â€” no access to private contributions yet

    Accuracy-wise, we go out of our way to avoid false credit or assumptions. Youâ€™ll only see what the candidate actually wrote.
  </Accordion>
  <Accordion title="Do candidates need to do anything to be evaluated?" icon="sparkles">
    Nope. As long as they share a public GitHub profile or repo link in their application or resume, we take it from there.
  </Accordion>
  <Accordion title="How do you determine what code the candidate wrote?">
    We only consider commits **authored by the candidate** â€” based on their GitHub username. We ignore contributions made by others in the repo.
  </Accordion>
  <Accordion title="What does the â€œQuality Gateâ€ mean?">
    Itâ€™s a quick **Pass / Fail** status based on SonarQubeâ€™s industry-standard metrics (code quality, bugs, vulnerabilities, etc.). Think of it like a basic health check for each project.
  </Accordion>
  <Accordion title="What does â€œOwnershipâ€ mean in a project?">
    We estimate what percentage of the project was written by the candidate â€” e.g. 100% (fully built), 50% (collaborated), or forked/copied.
  </Accordion>
  <Accordion title="How do you calculate â€œequivalent experienceâ€?">
    For each tech (e.g. Python), we break GitHub activity into **14-day blocks**. If a candidate commits code using that tech within a 14-day span, we count that as 2 weeks of experience. We sum these to estimate hands-on time.
  </Accordion>
</AccordionGroup>